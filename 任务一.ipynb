{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 任务一\n",
    "在任务一中，本小组选择Resnet18图像分类网络，实现了将Pytorch模型分别转换成Caffe模型与ONNX模型，并针对同一张测试图片，测试打印了三种模型下的推理结果置信度以及对于同一测试图片进行图像推理的模型吞吐量。置信度结果相差不大，可以忽略Pytorch向Caffe模型、ONNX模型转换后的精度损失。具体实现流程如下："
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.模型载入与转换\n",
    "#### 1.1 导入头文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#导入pytorch相关头文件\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "\n",
    "#导入caffe相关头文件\n",
    "import sys\n",
    "sys.path.append('/root/brocolli')\n",
    "from brocolli.converter.pytorch_caffe_parser import PytorchCaffeParser\n",
    "import caffe\n",
    "import numpy as np\n",
    "\n",
    "#导入onnx相关头文件\n",
    "import onnx\n",
    "import onnxruntime as ort\n",
    "import numpy as np\n",
    "import cv2\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 导入Resnet18神经网络的pytorch模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/caffe_0618/lib/python3.7/site-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n",
      "/root/miniconda3/envs/caffe_0618/lib/python3.7/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = models.resnet18(pretrained=True)\n",
    "net.eval()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3 实现pytorch模型转换成caffe模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-20 17:25:54.244 | DEBUG    | brocolli.converter.pytorch_graph:print_tabular:119 - \n",
      "opcode         name                   target                                                      args                                   kwargs\n",
      "-------------  ---------------------  ----------------------------------------------------------  -------------------------------------  --------\n",
      "placeholder    x                      x                                                           ()                                     {}\n",
      "call_module    conv1                  conv1                                                       (x,)                                   {}\n",
      "call_module    bn1                    bn1                                                         (conv1,)                               {}\n",
      "call_module    relu                   relu                                                        (bn1,)                                 {}\n",
      "call_module    maxpool                maxpool                                                     (relu,)                                {}\n",
      "call_module    layer1_0_conv1         layer1.0.conv1                                              (maxpool,)                             {}\n",
      "call_module    layer1_0_bn1           layer1.0.bn1                                                (layer1_0_conv1,)                      {}\n",
      "call_module    layer1_0_relu          layer1.0.relu                                               (layer1_0_bn1,)                        {}\n",
      "call_module    layer1_0_conv2         layer1.0.conv2                                              (layer1_0_relu,)                       {}\n",
      "call_module    layer1_0_bn2           layer1.0.bn2                                                (layer1_0_conv2,)                      {}\n",
      "call_function  add                    <built-in function add>                                     (layer1_0_bn2, maxpool)                {}\n",
      "call_module    layer1_0_relu_1        layer1.0.relu                                               (add,)                                 {}\n",
      "call_module    layer1_1_conv1         layer1.1.conv1                                              (layer1_0_relu_1,)                     {}\n",
      "call_module    layer1_1_bn1           layer1.1.bn1                                                (layer1_1_conv1,)                      {}\n",
      "call_module    layer1_1_relu          layer1.1.relu                                               (layer1_1_bn1,)                        {}\n",
      "call_module    layer1_1_conv2         layer1.1.conv2                                              (layer1_1_relu,)                       {}\n",
      "call_module    layer1_1_bn2           layer1.1.bn2                                                (layer1_1_conv2,)                      {}\n",
      "call_function  add_1                  <built-in function add>                                     (layer1_1_bn2, layer1_0_relu_1)        {}\n",
      "call_module    layer1_1_relu_1        layer1.1.relu                                               (add_1,)                               {}\n",
      "call_module    layer2_0_conv1         layer2.0.conv1                                              (layer1_1_relu_1,)                     {}\n",
      "call_module    layer2_0_bn1           layer2.0.bn1                                                (layer2_0_conv1,)                      {}\n",
      "call_module    layer2_0_relu          layer2.0.relu                                               (layer2_0_bn1,)                        {}\n",
      "call_module    layer2_0_conv2         layer2.0.conv2                                              (layer2_0_relu,)                       {}\n",
      "call_module    layer2_0_bn2           layer2.0.bn2                                                (layer2_0_conv2,)                      {}\n",
      "call_module    layer2_0_downsample_0  layer2.0.downsample.0                                       (layer1_1_relu_1,)                     {}\n",
      "call_module    layer2_0_downsample_1  layer2.0.downsample.1                                       (layer2_0_downsample_0,)               {}\n",
      "call_function  add_2                  <built-in function add>                                     (layer2_0_bn2, layer2_0_downsample_1)  {}\n",
      "call_module    layer2_0_relu_1        layer2.0.relu                                               (add_2,)                               {}\n",
      "call_module    layer2_1_conv1         layer2.1.conv1                                              (layer2_0_relu_1,)                     {}\n",
      "call_module    layer2_1_bn1           layer2.1.bn1                                                (layer2_1_conv1,)                      {}\n",
      "call_module    layer2_1_relu          layer2.1.relu                                               (layer2_1_bn1,)                        {}\n",
      "call_module    layer2_1_conv2         layer2.1.conv2                                              (layer2_1_relu,)                       {}\n",
      "call_module    layer2_1_bn2           layer2.1.bn2                                                (layer2_1_conv2,)                      {}\n",
      "call_function  add_3                  <built-in function add>                                     (layer2_1_bn2, layer2_0_relu_1)        {}\n",
      "call_module    layer2_1_relu_1        layer2.1.relu                                               (add_3,)                               {}\n",
      "call_module    layer3_0_conv1         layer3.0.conv1                                              (layer2_1_relu_1,)                     {}\n",
      "call_module    layer3_0_bn1           layer3.0.bn1                                                (layer3_0_conv1,)                      {}\n",
      "call_module    layer3_0_relu          layer3.0.relu                                               (layer3_0_bn1,)                        {}\n",
      "call_module    layer3_0_conv2         layer3.0.conv2                                              (layer3_0_relu,)                       {}\n",
      "call_module    layer3_0_bn2           layer3.0.bn2                                                (layer3_0_conv2,)                      {}\n",
      "call_module    layer3_0_downsample_0  layer3.0.downsample.0                                       (layer2_1_relu_1,)                     {}\n",
      "call_module    layer3_0_downsample_1  layer3.0.downsample.1                                       (layer3_0_downsample_0,)               {}\n",
      "call_function  add_4                  <built-in function add>                                     (layer3_0_bn2, layer3_0_downsample_1)  {}\n",
      "call_module    layer3_0_relu_1        layer3.0.relu                                               (add_4,)                               {}\n",
      "call_module    layer3_1_conv1         layer3.1.conv1                                              (layer3_0_relu_1,)                     {}\n",
      "call_module    layer3_1_bn1           layer3.1.bn1                                                (layer3_1_conv1,)                      {}\n",
      "call_module    layer3_1_relu          layer3.1.relu                                               (layer3_1_bn1,)                        {}\n",
      "call_module    layer3_1_conv2         layer3.1.conv2                                              (layer3_1_relu,)                       {}\n",
      "call_module    layer3_1_bn2           layer3.1.bn2                                                (layer3_1_conv2,)                      {}\n",
      "call_function  add_5                  <built-in function add>                                     (layer3_1_bn2, layer3_0_relu_1)        {}\n",
      "call_module    layer3_1_relu_1        layer3.1.relu                                               (add_5,)                               {}\n",
      "call_module    layer4_0_conv1         layer4.0.conv1                                              (layer3_1_relu_1,)                     {}\n",
      "call_module    layer4_0_bn1           layer4.0.bn1                                                (layer4_0_conv1,)                      {}\n",
      "call_module    layer4_0_relu          layer4.0.relu                                               (layer4_0_bn1,)                        {}\n",
      "call_module    layer4_0_conv2         layer4.0.conv2                                              (layer4_0_relu,)                       {}\n",
      "call_module    layer4_0_bn2           layer4.0.bn2                                                (layer4_0_conv2,)                      {}\n",
      "call_module    layer4_0_downsample_0  layer4.0.downsample.0                                       (layer3_1_relu_1,)                     {}\n",
      "call_module    layer4_0_downsample_1  layer4.0.downsample.1                                       (layer4_0_downsample_0,)               {}\n",
      "call_function  add_6                  <built-in function add>                                     (layer4_0_bn2, layer4_0_downsample_1)  {}\n",
      "call_module    layer4_0_relu_1        layer4.0.relu                                               (add_6,)                               {}\n",
      "call_module    layer4_1_conv1         layer4.1.conv1                                              (layer4_0_relu_1,)                     {}\n",
      "call_module    layer4_1_bn1           layer4.1.bn1                                                (layer4_1_conv1,)                      {}\n",
      "call_module    layer4_1_relu          layer4.1.relu                                               (layer4_1_bn1,)                        {}\n",
      "call_module    layer4_1_conv2         layer4.1.conv2                                              (layer4_1_relu,)                       {}\n",
      "call_module    layer4_1_bn2           layer4.1.bn2                                                (layer4_1_conv2,)                      {}\n",
      "call_function  add_7                  <built-in function add>                                     (layer4_1_bn2, layer4_0_relu_1)        {}\n",
      "call_module    layer4_1_relu_1        layer4.1.relu                                               (add_7,)                               {}\n",
      "call_module    avgpool                avgpool                                                     (layer4_1_relu_1,)                     {}\n",
      "call_function  flatten                <built-in method flatten of type object at 0x7f475eae1380>  (avgpool, 1)                           {}\n",
      "call_module    fc                     fc                                                          (flatten,)                             {}\n",
      "output         output                 output                                                      (fc,)                                  {}\n",
      "2023-06-20 17:25:56.002 | INFO     | brocolli.converter.pytorch_caffe_parser:save:57 - prototxt saved to resnet18.prototxt\n",
      "2023-06-20 17:25:56.004 | INFO     | brocolli.converter.pytorch_caffe_parser:save:58 - caffemodel saved to resnet18.caffemodel\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(1, 3, 224, 224)\n",
    "pytorch_parser = PytorchCaffeParser(net, x)\n",
    "pytorch_parser.convert()\n",
    "pytorch_parser.save('resnet18')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4 实现pytorch模型转换成onnx模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = models.resnet18(pretrained=True)\n",
    "x = torch.rand(1, 3, 224, 224)\n",
    "torch.onnx.export(net, x, 'resnet18.onnx')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 准确性损失评估\n",
    "### 2.1 载入图片并进行预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../images/dog.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1861/3436057710.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m#载入图片\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0;34m\"../images/dog.jpg\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mIPythonImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/caffe_0618/lib/python3.7/site-packages/IPython/core/display.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, url, filename, format, embed, width, height, retina, unconfined, metadata)\u001b[0m\n\u001b[1;32m   1230\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munconfined\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munconfined\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1231\u001b[0m         super(Image, self).__init__(data=data, url=url, filename=filename, \n\u001b[0;32m-> 1232\u001b[0;31m                 metadata=metadata)\n\u001b[0m\u001b[1;32m   1233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1234\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwidth\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'width'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/caffe_0618/lib/python3.7/site-packages/IPython/core/display.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, url, filename, metadata)\u001b[0m\n\u001b[1;32m    635\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 637\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    638\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    639\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/caffe_0618/lib/python3.7/site-packages/IPython/core/display.py\u001b[0m in \u001b[0;36mreload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1261\u001b[0m         \u001b[0;34m\"\"\"Reload the raw data from file or URL.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1262\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1263\u001b[0;31m             \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1264\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretina\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1265\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_retina_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/caffe_0618/lib/python3.7/site-packages/IPython/core/display.py\u001b[0m in \u001b[0;36mreload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    660\u001b[0m         \u001b[0;34m\"\"\"Reload the raw data from file or URL.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    661\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilename\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 662\u001b[0;31m             \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_flags\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    663\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    664\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murl\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../images/dog.jpg'"
     ]
    }
   ],
   "source": [
    "from PIL import Image as PILImage\n",
    "from timm.data import resolve_data_config\n",
    "from timm.data.transforms_factory import create_transform\n",
    "from IPython.display import Image as IPythonImage\n",
    "\n",
    "config = resolve_data_config({}, model=net)\n",
    "transform = create_transform(**config)\n",
    "#载入图片\n",
    "filename =  \"../images/dog.jpg\"\n",
    "IPythonImage(filename=filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compose(\n",
      "    Resize(size=256, interpolation=bicubic, max_size=None, antialias=None)\n",
      "    CenterCrop(size=(224, 224))\n",
      "    ToTensor()\n",
      "    Normalize(mean=tensor([0.4850, 0.4560, 0.4060]), std=tensor([0.2290, 0.2240, 0.2250]))\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#图像预处理\n",
    "print(transform)\n",
    "img = PILImage.open(filename).convert('RGB')\n",
    "tensor = transform(img).unsqueeze(0) # transform and add batch dimension\n",
    "\n",
    "#载入标签文件\n",
    "with open(\"../data/imagenet_classes.txt\", \"r\") as f:\n",
    "    categories = [s.strip() for s in f.readlines()]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 图像推理\n",
    "将预处理后的图像输入到推理框架之中进行图像推理，分别测试pytorch、caffe、onnx三个框架模型中的推理结果，比较pytorch分别向caffe模型、onnx模型转换后的精度损失\n",
    "#### 2.2.1 Pytorch（Top-5）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'models' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1326/514618571.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresnet18\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'models' is not defined"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "net = models.resnet18(pretrained=True)\n",
    "net.eval()\n",
    "with torch.no_grad():\n",
    "    out = net(tensor)\n",
    "\n",
    "NUM_IMAGES = 1000  # 测试推理的图像数量\n",
    "start_time = time.time()\n",
    "for _ in range(NUM_IMAGES):\n",
    "    probabilities = torch.nn.functional.softmax(out[0], dim=0)\n",
    "end_time = time.time()\n",
    "\n",
    "#计算打印置信度top5和对应的标签\n",
    "probabilities = torch.nn.functional.softmax(out[0], dim=0)\n",
    "top5_prob, top5_catid = torch.topk(probabilities, 5)\n",
    "for i in range(top5_prob.size(0)):\n",
    "    print(categories[top5_catid[i]], top5_prob[i].item())\n",
    "\n",
    "#计算打印吞吐量\n",
    "total_time = end_time - start_time\n",
    "throughput = NUM_IMAGES / total_time\n",
    "print(f'Throughput: {throughput} images/second')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.2 Caffe（Top-5）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W20230620 01:05:20.321411   537 _caffe.cpp:122] DEPRECATION WARNING - deprecated use of Python interface\n",
      "W20230620 01:05:20.321446   537 _caffe.cpp:123] Use this instead (with the named \"weights\" parameter):\n",
      "W20230620 01:05:20.321449   537 _caffe.cpp:125] Net('./resnet18.prototxt', 1, weights='./resnet18.caffemodel')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samoyed 0.89802784\n",
      "white wolf 0.0439865\n",
      "Arctic fox 0.03794145\n",
      "Pomeranian 0.0047865086\n",
      "West Highland white terrier 0.0033660661\n",
      "Throughput: 16.401650354125227 images/second\n"
     ]
    }
   ],
   "source": [
    "# 定义模型文件和权重文件的路径\n",
    "model_file = './resnet18.prototxt'\n",
    "weight_file = './resnet18.caffemodel'\n",
    "# 加载模型和权重\n",
    "net = caffe.Net(model_file, weight_file, caffe.TEST)\n",
    "# 定义输入数据的形状\n",
    "net.blobs['x'].reshape(1, 3, 224, 224)\n",
    "# 将输入数据设置为网络的输入\n",
    "net.blobs['x'].data[...] = tensor\n",
    "net.forward()# 进行前向推理\n",
    "output = net.blobs['fc'].data[0] #获取网络的输出\n",
    "\n",
    "NUM_IMAGES = 1000  # 测试推理的图像数量\n",
    "start_time = time.time()\n",
    "for _ in range(NUM_IMAGES):\n",
    "    softmax = np.exp(output) / np.sum(np.exp(output))\n",
    "    sorted_indices = np.argsort(-softmax)\n",
    "end_time = time.time()\n",
    "\n",
    "#计算打印置信度top5和对应的标签\n",
    "top_5_indices = sorted_indices[:5]\n",
    "for idx in top_5_indices:\n",
    "    print(categories[idx], softmax[idx])\n",
    "\n",
    "#计算打印吞吐量\n",
    "total_time = end_time - start_time\n",
    "throughput = NUM_IMAGES / total_time\n",
    "print(f'Throughput: {throughput} images/second')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.3 ONNX（Top-5）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samoyed 0.8980278968811035\n",
      "white wolf 0.04398662969470024\n",
      "Arctic fox 0.03794185072183609\n",
      "Pomeranian 0.004786513280123472\n",
      "West Highland white terrier 0.0033660889603197575\n",
      "Throughput: 93.2584663389353 images/second\n"
     ]
    }
   ],
   "source": [
    "model = ort.InferenceSession(\"resnet18.onnx\")\n",
    "input_name = model.get_inputs()[0].name\n",
    "output_name = model.get_outputs()[0].name\n",
    "outputs = model.run([output_name], {input_name: tensor.numpy()})\n",
    "output_tensor = torch.Tensor(outputs[0])\n",
    "\n",
    "NUM_IMAGES = 1000  # 测试推理的图像数量\n",
    "start_time = time.time()\n",
    "for _ in range(NUM_IMAGES):\n",
    "    probabilities = torch.nn.functional.softmax(output_tensor[0], dim=0)\n",
    "end_time = time.time()\n",
    "\n",
    "#计算打印置信度top5和对应的标签\n",
    "probabilities = torch.nn.functional.softmax(output_tensor[0], dim=0)\n",
    "top5_prob, top5_catid = torch.topk(probabilities, 5)\n",
    "for i in range(top5_prob.size(0)):\n",
    "    print(categories[top5_catid[i]], top5_prob[i].item())\n",
    "\n",
    "#计算打印吞吐量\n",
    "total_time = end_time - start_time\n",
    "throughput = NUM_IMAGES / total_time\n",
    "print(f'Throughput: {throughput} images/second')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 综上可知，Pytorch2Caffe、Pytorch2onnx的模型转换成功，精度损失可以忽略"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "caffe_0618",
   "language": "python",
   "name": "caffe_0618"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
