{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5ff5b116-d83d-43b0-8004-dd3731dee90c",
   "metadata": {},
   "source": [
    "## Task 2\n",
    "### 思路一：使用改进后的Caffe2Darknet转换模型，并测试推理能力"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "317395e6-f89d-477a-a4d2-03fc94d5a384",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from caffe2darknet.ipynb\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('/root/darknet') # path of darknet\n",
    "from caffe2darknet import Caffe2Darknet # 自己实现的转换\n",
    "\n",
    "from timm.data import resolve_data_config\n",
    "from timm.data.transforms_factory import create_transform\n",
    "import torchvision.models as models\n",
    "from PIL import Image as PILImage\n",
    "from IPython.display import Image as IPythonImage\n",
    "\n",
    "import darknet\n",
    "import darknet_images\n",
    "\n",
    "import caffe\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ffe58be0-b5f4-4eb9-a0a2-3824ac00e597",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file = './resnet18.prototxt'\n",
    "weight_file = './resnet18.caffemodel'\n",
    "out_file_path = './out/resnet18.cfg'\n",
    "c2d = Caffe2Darknet(net = model_file,\n",
    "                        weight = weight_file,\n",
    "                        out_file = out_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "443244d7-a46e-4804-aba7-f39b1b4c6549",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading caffemodel:  ./ResNet18/resnet18.caffemodel\n",
      "0 conv1 Convolution\n",
      "1 bn1_bn BatchNorm\n",
      "2 bn1 Scale\n",
      "3 relu ReLU\n",
      "4 maxpool Pooling\n",
      "5 layer1_0_conv1 Convolution\n",
      "6 layer1_0_bn1_bn BatchNorm\n",
      "7 layer1_0_bn1 Scale\n",
      "8 layer1_0_relu ReLU\n",
      "9 layer1_0_conv2 Convolution\n",
      "10 layer1_0_bn2_bn BatchNorm\n",
      "11 layer1_0_bn2 Scale\n",
      "12 add Eltwise\n",
      "14 layer1_1_conv1 Convolution\n",
      "15 layer1_1_bn1_bn BatchNorm\n",
      "16 layer1_1_bn1 Scale\n",
      "17 layer1_1_relu ReLU\n",
      "18 layer1_1_conv2 Convolution\n",
      "19 layer1_1_bn2_bn BatchNorm\n",
      "20 layer1_1_bn2 Scale\n",
      "21 add_1 Eltwise\n",
      "23 layer2_0_conv1 Convolution\n",
      "24 layer2_0_bn1_bn BatchNorm\n",
      "25 layer2_0_bn1 Scale\n",
      "26 layer2_0_relu ReLU\n",
      "27 layer2_0_conv2 Convolution\n",
      "28 layer2_0_bn2_bn BatchNorm\n",
      "29 layer2_0_bn2 Scale\n",
      "30 layer2_0_downsample_0 Convolution\n",
      "31 layer2_0_downsample_1_bn BatchNorm\n",
      "32 layer2_0_downsample_1 Scale\n",
      "33 add_2 Eltwise\n",
      "35 layer2_1_conv1 Convolution\n",
      "36 layer2_1_bn1_bn BatchNorm\n",
      "37 layer2_1_bn1 Scale\n",
      "38 layer2_1_relu ReLU\n",
      "39 layer2_1_conv2 Convolution\n",
      "40 layer2_1_bn2_bn BatchNorm\n",
      "41 layer2_1_bn2 Scale\n",
      "42 add_3 Eltwise\n",
      "44 layer3_0_conv1 Convolution\n",
      "45 layer3_0_bn1_bn BatchNorm\n",
      "46 layer3_0_bn1 Scale\n",
      "47 layer3_0_relu ReLU\n",
      "48 layer3_0_conv2 Convolution\n",
      "49 layer3_0_bn2_bn BatchNorm\n",
      "50 layer3_0_bn2 Scale\n",
      "51 layer3_0_downsample_0 Convolution\n",
      "52 layer3_0_downsample_1_bn BatchNorm\n",
      "53 layer3_0_downsample_1 Scale\n",
      "54 add_4 Eltwise\n",
      "56 layer3_1_conv1 Convolution\n",
      "57 layer3_1_bn1_bn BatchNorm\n",
      "58 layer3_1_bn1 Scale\n",
      "59 layer3_1_relu ReLU\n",
      "60 layer3_1_conv2 Convolution\n",
      "61 layer3_1_bn2_bn BatchNorm\n",
      "62 layer3_1_bn2 Scale\n",
      "63 add_5 Eltwise\n",
      "65 layer4_0_conv1 Convolution\n",
      "66 layer4_0_bn1_bn BatchNorm\n",
      "67 layer4_0_bn1 Scale\n",
      "68 layer4_0_relu ReLU\n",
      "69 layer4_0_conv2 Convolution\n",
      "70 layer4_0_bn2_bn BatchNorm\n",
      "71 layer4_0_bn2 Scale\n",
      "72 layer4_0_downsample_0 Convolution\n",
      "73 layer4_0_downsample_1_bn BatchNorm\n",
      "74 layer4_0_downsample_1 Scale\n",
      "75 add_6 Eltwise\n",
      "77 layer4_1_conv1 Convolution\n",
      "78 layer4_1_bn1_bn BatchNorm\n",
      "79 layer4_1_bn1 Scale\n",
      "80 layer4_1_relu ReLU\n",
      "81 layer4_1_conv2 Convolution\n",
      "82 layer4_1_bn2_bn BatchNorm\n",
      "83 layer4_1_bn2 Scale\n",
      "84 add_7 Eltwise\n",
      "86 avgpool Pooling\n",
      "87 flatten Flatten\n",
      "88 fc InnerProduct\n",
      "done\n",
      "Save to  ./out_dir/resnet182.weights\n",
      "[net]\n",
      "batch=1\n",
      "channels=3\n",
      "height=224\n",
      "width=224\n",
      "\n",
      "[convolutional]\n",
      "filters=64\n",
      "size=7\n",
      "stride=2\n",
      "pad=1\n",
      "batch_normalize=1\n",
      "activation=relu\n",
      "\n",
      "[maxpool]\n",
      "size=3\n",
      "stride=2\n",
      "pad=1\n",
      "\n",
      "[convolutional]\n",
      "filters=64\n",
      "size=3\n",
      "stride=1\n",
      "pad=1\n",
      "batch_normalize=1\n",
      "activation=relu\n",
      "\n",
      "[convolutional]\n",
      "filters=64\n",
      "size=3\n",
      "stride=1\n",
      "pad=1\n",
      "batch_normalize=1\n",
      "activation=linear\n",
      "\n",
      "[shortcut]\n",
      "from=-3\n",
      "activation=relu\n",
      "\n",
      "[convolutional]\n",
      "filters=64\n",
      "size=3\n",
      "stride=1\n",
      "pad=1\n",
      "batch_normalize=1\n",
      "activation=relu\n",
      "\n",
      "[convolutional]\n",
      "filters=64\n",
      "size=3\n",
      "stride=1\n",
      "pad=1\n",
      "batch_normalize=1\n",
      "activation=linear\n",
      "\n",
      "[shortcut]\n",
      "from=-3\n",
      "activation=relu\n",
      "\n",
      "[convolutional]\n",
      "filters=128\n",
      "size=3\n",
      "stride=2\n",
      "pad=1\n",
      "batch_normalize=1\n",
      "activation=relu\n",
      "\n",
      "[convolutional]\n",
      "filters=128\n",
      "size=3\n",
      "stride=1\n",
      "pad=1\n",
      "batch_normalize=1\n",
      "activation=linear\n",
      "\n",
      "[route]\n",
      "layers=-3\n",
      "\n",
      "[convolutional]\n",
      "filters=128\n",
      "size=1\n",
      "stride=2\n",
      "pad=1\n",
      "batch_normalize=1\n",
      "activation=linear\n",
      "\n",
      "[shortcut]\n",
      "from=-3\n",
      "activation=relu\n",
      "\n",
      "[convolutional]\n",
      "filters=128\n",
      "size=3\n",
      "stride=1\n",
      "pad=1\n",
      "batch_normalize=1\n",
      "activation=relu\n",
      "\n",
      "[convolutional]\n",
      "filters=128\n",
      "size=3\n",
      "stride=1\n",
      "pad=1\n",
      "batch_normalize=1\n",
      "activation=linear\n",
      "\n",
      "[shortcut]\n",
      "from=-3\n",
      "activation=relu\n",
      "\n",
      "[convolutional]\n",
      "filters=256\n",
      "size=3\n",
      "stride=2\n",
      "pad=1\n",
      "batch_normalize=1\n",
      "activation=relu\n",
      "\n",
      "[convolutional]\n",
      "filters=256\n",
      "size=3\n",
      "stride=1\n",
      "pad=1\n",
      "batch_normalize=1\n",
      "activation=linear\n",
      "\n",
      "[route]\n",
      "layers=-3\n",
      "\n",
      "[convolutional]\n",
      "filters=256\n",
      "size=1\n",
      "stride=2\n",
      "pad=1\n",
      "batch_normalize=1\n",
      "activation=linear\n",
      "\n",
      "[shortcut]\n",
      "from=-3\n",
      "activation=relu\n",
      "\n",
      "[convolutional]\n",
      "filters=256\n",
      "size=3\n",
      "stride=1\n",
      "pad=1\n",
      "batch_normalize=1\n",
      "activation=relu\n",
      "\n",
      "[convolutional]\n",
      "filters=256\n",
      "size=3\n",
      "stride=1\n",
      "pad=1\n",
      "batch_normalize=1\n",
      "activation=linear\n",
      "\n",
      "[shortcut]\n",
      "from=-3\n",
      "activation=relu\n",
      "\n",
      "[convolutional]\n",
      "filters=512\n",
      "size=3\n",
      "stride=2\n",
      "pad=1\n",
      "batch_normalize=1\n",
      "activation=relu\n",
      "\n",
      "[convolutional]\n",
      "filters=512\n",
      "size=3\n",
      "stride=1\n",
      "pad=1\n",
      "batch_normalize=1\n",
      "activation=linear\n",
      "\n",
      "[route]\n",
      "layers=-3\n",
      "\n",
      "[convolutional]\n",
      "filters=512\n",
      "size=1\n",
      "stride=2\n",
      "pad=1\n",
      "batch_normalize=1\n",
      "activation=linear\n",
      "\n",
      "[shortcut]\n",
      "from=-3\n",
      "activation=relu\n",
      "\n",
      "[convolutional]\n",
      "filters=512\n",
      "size=3\n",
      "stride=1\n",
      "pad=1\n",
      "batch_normalize=1\n",
      "activation=relu\n",
      "\n",
      "[convolutional]\n",
      "filters=512\n",
      "size=3\n",
      "stride=1\n",
      "pad=1\n",
      "batch_normalize=1\n",
      "activation=linear\n",
      "\n",
      "[shortcut]\n",
      "from=-3\n",
      "activation=relu\n",
      "\n",
      "[avgpool]\n",
      "\n",
      "[connected]\n",
      "output=512\n",
      "activation=linear\n",
      "\n",
      "[connected]\n",
      "output=1000\n",
      "activation=linear\n",
      "\n",
      "layer     filters    size              input                output\n",
      "    0 conv     64  7 x 7 / 2   224 x 224                 x   3   ->   112 x 112 x  64\n",
      "    1 max          3 x 3 / 2   112                 x 112 x  64   ->    56 x  56 x  64\n",
      "    2 conv     64  3 x 3 / 1    56 x  56                 x  64   ->    56 x  56 x  64\n",
      "    3 conv     64  3 x 3 / 1    56 x  56                 x  64   ->    56 x  56 x  64\n",
      "    4 shortcut 1\n",
      "    5 conv     64  3 x 3 / 1    56 x  56                 x  64   ->    56 x  56 x  64\n",
      "    6 conv     64  3 x 3 / 1    56 x  56                 x  64   ->    56 x  56 x  64\n",
      "    7 shortcut 4\n",
      "    8 conv    128  3 x 3 / 2    56 x  56                 x  64   ->    28 x  28 x 128\n",
      "    9 conv    128  3 x 3 / 1    28 x  28                 x 128   ->    28 x  28 x 128\n",
      "   10 route  7\n",
      "   11 conv    128  1 x 1 / 2    56 x  56                 x  64   ->    28 x  28 x 128\n",
      "   12 shortcut 9\n",
      "   13 conv    128  3 x 3 / 1    28 x  28                 x 128   ->    28 x  28 x 128\n",
      "   14 conv    128  3 x 3 / 1    28 x  28                 x 128   ->    28 x  28 x 128\n",
      "   15 shortcut 12\n",
      "   16 conv    256  3 x 3 / 2    28 x  28                 x 128   ->    14 x  14 x 256\n",
      "   17 conv    256  3 x 3 / 1    14 x  14                 x 256   ->    14 x  14 x 256\n",
      "   18 route  15\n",
      "   19 conv    256  1 x 1 / 2    28 x  28                 x 128   ->    14 x  14 x 256\n",
      "   20 shortcut 17\n",
      "   21 conv    256  3 x 3 / 1    14 x  14                 x 256   ->    14 x  14 x 256\n",
      "   22 conv    256  3 x 3 / 1    14 x  14                 x 256   ->    14 x  14 x 256\n",
      "   23 shortcut 20\n",
      "   24 conv    512  3 x 3 / 2    14 x  14                 x 256   ->     7 x   7 x 512\n",
      "   25 conv    512  3 x 3 / 1     7 x   7                 x 512   ->     7 x   7 x 512\n",
      "   26 route  23\n",
      "   27 conv    512  1 x 1 / 2    14 x  14                 x 256   ->     7 x   7 x 512\n",
      "   28 shortcut 25\n",
      "   29 conv    512  3 x 3 / 1     7 x   7                 x 512   ->     7 x   7 x 512\n",
      "   30 conv    512  3 x 3 / 1     7 x   7                 x 512   ->     7 x   7 x 512\n",
      "   31 shortcut 28\n",
      "   32 avg                        7 x   7 x 512   ->      512\n",
      "   33 connected                            512  ->      512\n",
      "   34 connected                            512  ->      1000\n",
      "Hash of Darknet model has been published:  81b96cad083faf3760c19e1e46f6c3d0\n"
     ]
    }
   ],
   "source": [
    "c2d.convert()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "688e9dd6",
   "metadata": {},
   "source": [
    "## 准确性评估"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c030df3c-0134-46d3-83ae-cdc579fb5027",
   "metadata": {},
   "source": [
    "### 推理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ba545f0-e016-4d85-a007-a2a81e716a73",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/caffe_0618/lib/python3.7/site-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n",
      "/root/miniconda3/envs/caffe_0618/lib/python3.7/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "net = models.resnet18(pretrained=False)\n",
    "config = resolve_data_config({}, model=net)\n",
    "transform = create_transform(**config)\n",
    "img = PILImage.open('./image/dog.jpg').convert('RGB')\n",
    "tensor = transform(img).unsqueeze(0)\n",
    "image = tensor.clone().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd3e365c-47ac-49b5-bf8e-e315457515c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "max_batches: Using default '0'\n",
      "learning_rate: Using default '0.001000'\n",
      "momentum: Using default '0.900000'\n",
      "decay: Using default '0.000100'\n",
      "subdivisions: Using default '1'\n",
      "policy: Using default 'constant'\n",
      "   layer   filters  size/strd(dil)      input                output\n",
      "   0 conv     64       7 x 7/ 2    224 x 224 x   3 ->  112 x 112 x  64 0.236 BF\n",
      "   1 max                3x 3/ 2    112 x 112 x  64 ->   56 x  56 x  64 0.002 BF\n",
      "Unused field: 'pad = 1'\n",
      "   2 conv     64       3 x 3/ 1     56 x  56 x  64 ->   56 x  56 x  64 0.231 BF\n",
      "   3 conv     64       3 x 3/ 1     56 x  56 x  64 ->   56 x  56 x  64 0.231 BF\n",
      "   4 Shortcut Layer: 1,  wt = 0, wn = 0, outputs:  56 x  56 x  64 0.000 BF\n",
      "   5 conv     64       3 x 3/ 1     56 x  56 x  64 ->   56 x  56 x  64 0.231 BF\n",
      "   6 conv     64       3 x 3/ 1     56 x  56 x  64 ->   56 x  56 x  64 0.231 BF\n",
      "   7 Shortcut Layer: 4,  wt = 0, wn = 0, outputs:  56 x  56 x  64 0.000 BF\n",
      "   8 conv    128       3 x 3/ 2     56 x  56 x  64 ->   28 x  28 x 128 0.116 BF\n",
      "   9 conv    128       3 x 3/ 1     28 x  28 x 128 ->   28 x  28 x 128 0.231 BF\n",
      "  10 route  7 \t\t                           ->   56 x  56 x  64 \n",
      "  11 conv    128       1 x 1/ 2     56 x  56 x  64 ->   28 x  28 x 128 0.013 BF\n",
      "  12 Shortcut Layer: 9,  wt = 0, wn = 0, outputs:  28 x  28 x 128 0.000 BF\n",
      "  13 conv    128       3 x 3/ 1     28 x  28 x 128 ->   28 x  28 x 128 0.231 BF\n",
      "  14 conv    128       3 x 3/ 1     28 x  28 x 128 ->   28 x  28 x 128 0.231 BF\n",
      "  15 Shortcut Layer: 12,  wt = 0, wn = 0, outputs:  28 x  28 x 128 0.000 BF\n",
      "  16 conv    256       3 x 3/ 2     28 x  28 x 128 ->   14 x  14 x 256 0.116 BF\n",
      "  17 conv    256       3 x 3/ 1     14 x  14 x 256 ->   14 x  14 x 256 0.231 BF\n",
      "  18 route  15 \t\t                           ->   28 x  28 x 128 \n",
      "  19 conv    256       1 x 1/ 2     28 x  28 x 128 ->   14 x  14 x 256 0.013 BF\n",
      "  20 Shortcut Layer: 17,  wt = 0, wn = 0, outputs:  14 x  14 x 256 0.000 BF\n",
      "  21 conv    256       3 x 3/ 1     14 x  14 x 256 ->   14 x  14 x 256 0.231 BF\n",
      "  22 conv    256       3 x 3/ 1     14 x  14 x 256 ->   14 x  14 x 256 0.231 BF\n",
      "  23 Shortcut Layer: 20,  wt = 0, wn = 0, outputs:  14 x  14 x 256 0.000 BF\n",
      "  24 conv    512       3 x 3/ 2     14 x  14 x 256 ->    7 x   7 x 512 0.116 BF\n",
      "  25 conv    512       3 x 3/ 1      7 x   7 x 512 ->    7 x   7 x 512 0.231 BF\n",
      "  26 route  23 \t\t                           ->   14 x  14 x 256 \n",
      "  27 conv    512       1 x 1/ 2     14 x  14 x 256 ->    7 x   7 x 512 0.013 BF\n",
      "  28 Shortcut Layer: 25,  wt = 0, wn = 0, outputs:   7 x   7 x 512 0.000 BF\n",
      "  29 conv    512       3 x 3/ 1      7 x   7 x 512 ->    7 x   7 x 512 0.231 BF\n",
      "  30 conv    512       3 x 3/ 1      7 x   7 x 512 ->    7 x   7 x 512 0.231 BF\n",
      "  31 Shortcut Layer: 28,  wt = 0, wn = 0, outputs:   7 x   7 x 512 0.000 BF\n",
      "  32 avg                             7 x   7 x 512 ->    512\n",
      "  33 connected                             512  ->   512\n",
      "  34 connected                             512  ->  1000\n",
      "Total BFLOPS 3.630 \n",
      "avg_outputs = 114812 \n",
      "Loading weights from ./out_dir/resnet182.weights...Done! Loaded 34 layers from weights-file \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Try to load cfg: ./out_dir/resnet182.cfg, weights: ./out_dir/resnet182.weights, clear = 0 \n",
      "mini_batch = 1, batch = 1, time_steps = 1, train = 0 \n",
      " Try to load weights: ./out_dir/resnet182.weights \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('cocker spaniel', 5.662687301635742),\n",
       " (\"yellow lady's slipper\", 5.231784820556641),\n",
       " ('umbrella', 4.674552917480469),\n",
       " ('Brittany spaniel', 4.525413513183594),\n",
       " ('balloon', 4.159382343292236)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network_path = \"./out_dir/resnet18.cfg\"\n",
    "label_path = \"./imagenet1k.data\"\n",
    "weights_path = \"./out_dir/resnet182.weights\"\n",
    "network, class_names, class_colors = darknet.load_network(network_path, label_path, weights_path, 1)\n",
    "result = darknet_images.image_classification(image, network, class_names)\n",
    "result[:5]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "caffe_0618",
   "language": "python",
   "name": "caffe_0618"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
